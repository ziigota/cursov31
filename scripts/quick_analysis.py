"""
–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Spotify –ë–ï–ó –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã –∏–∑ backend/services/
—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥!

–ó–∞–ø—É—Å–∫: python scripts/quick_analysis.py
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.insert(0, str(Path(__file__).parent.parent))

import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ —Å–µ—Ä–≤–∏—Å—ã
from backend.config import DATASET_PATH, PLOTS_DIR
from backend.services.data_service import data_service
from backend.services.analysis_service import analysis_service
from backend.services.plot_service import plot_service
from backend.services.model_service import model_service

# –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏–∑ base64
import base64
import re

def save_base64_image(base64_string: str, filename: str):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª"""
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å data:image/png;base64,
    image_data = re.sub('^data:image/.+;base64,', '', base64_string)

    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    with open(PLOTS_DIR / filename, 'wb') as f:
        f.write(base64.b64decode(image_data))


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""

    print("="*70)
    print("üéµ –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó SPOTIFY –¢–†–ï–ö–û–í")
    print("="*70)

    # ==================== 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ====================
    print("\n[1/9] üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")

    if not DATASET_PATH.exists():
        print(f"‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {DATASET_PATH}")
        print("\nüì• –°–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle:")
        print("   https://www.kaggle.com/datasets/zaheenhamidani/ultimate-spotify-tracks-db")
        print("   –ü–æ–º–µ—Å—Ç–∏—Ç–µ SpotifyFeatures.csv –≤ –ø–∞–ø–∫—É data/")
        return

    if not data_service.load_dataset(DATASET_PATH):
        print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞")
        return

    df = data_service.get_dataframe()
    info = data_service.get_info()

    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {info['rows']:,} —Å—Ç—Ä–æ–∫ √ó {info['columns']} –∫–æ–ª–æ–Ω–æ–∫")
    print(f"üìä –ü—Ä–∏–∑–Ω–∞–∫–∏: {', '.join(info['features'][:10])}...")

    # ==================== 2. –í–û–ü–†–û–° 1: –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø ====================
    print("\n[2/9] üìà –í–û–ü–†–û–° 1: –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π...")

    distributions = analysis_service.analyze_distributions(df)

    for feature, stats in distributions['distributions'].items():
        print(f"\n  {feature.upper()}:")
        print(f"    –°—Ä–µ–¥–Ω–µ–µ:  {stats['mean']:.2f}")
        print(f"    –ú–µ–¥–∏–∞–Ω–∞:  {stats['median']:.2f}")
        print(f"    –°—Ç.–æ—Ç–∫–ª.: {stats['std']:.2f}")
        print(f"    –î–∏–∞–ø–∞–∑–æ–Ω: {stats['min']:.2f} - {stats['max']:.2f}")

    # ==================== 3. –í–û–ü–†–û–° 2: –ö–û–†–†–ï–õ–Ø–¶–ò–ò ====================
    print("\n[3/9] üîó –í–û–ü–†–û–° 2: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å—é...")

    correlations = analysis_service.analyze_correlations(df)

    print("\n  ‚úÖ –¢–æ–ø-3 –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:")
    for feature, corr in correlations['top_positive'].items():
        print(f"    {feature:20s}: {corr:+.4f}")

    print("\n  ‚ùå –¢–æ–ø-3 –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:")
    for feature, corr in correlations['top_negative'].items():
        print(f"    {feature:20s}: {corr:+.4f}")

    # ==================== 4. –í–û–ü–†–û–° 3: –ñ–ê–ù–†–´ ====================
    print("\n[4/9] üé∏ –í–û–ü–†–û–° 3: –ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤...")

    try:
        genres = analysis_service.analyze_genres(df)
        print(f"\n  üìä –ù–∞–π–¥–µ–Ω–æ –∂–∞–Ω—Ä–æ–≤: {genres['genre_count']}")
        print(f"  üéµ –í—Å–µ–≥–æ —Ç—Ä–µ–∫–æ–≤: {genres['total_tracks']:,}")

        print(f"\n  –¢–æ–ø-5 –∂–∞–Ω—Ä–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É:")
        for genre in genres['top_genres']:
            count = genres['genre_counts'][genre]
            print(f"    {genre:30s}: {count:6,} —Ç—Ä–µ–∫–æ–≤")
    except ValueError as e:
        print(f"  ‚ö†Ô∏è {e}")

    # ==================== 5. –ì–†–ê–§–ò–ö 1: SCATTER ====================
    print("\n[5/9] üìä –ì—Ä–∞—Ñ–∏–∫ 1: Scatter plot (—Ç–µ–º–ø vs –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å)...")

    scatter_image = plot_service.create_scatter_plot(df, 'tempo', 'popularity')
    save_base64_image(scatter_image, 'scatter_tempo_popularity.png')
    print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {PLOTS_DIR / 'scatter_tempo_popularity.png'}")

    # ==================== 6. –ì–†–ê–§–ò–ö 2: HISTOGRAM ====================
    print("\n[6/9] üìä –ì—Ä–∞—Ñ–∏–∫ 2: Histogram (—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥—Ä–æ–º–∫–æ—Å—Ç–∏)...")

    histogram_image = plot_service.create_histogram(df, 'loudness')
    save_base64_image(histogram_image, 'histogram_loudness.png')
    print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {PLOTS_DIR / 'histogram_loudness.png'}")

    # ==================== 7. –ì–†–ê–§–ò–ö 3: HEATMAP ====================
    print("\n[7/9] üìä –ì—Ä–∞—Ñ–∏–∫ 3: Heatmap (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞)...")

    corr_matrix = analysis_service.get_correlation_matrix(df)
    heatmap_image = plot_service.create_heatmap(corr_matrix)
    save_base64_image(heatmap_image, 'heatmap_correlations.png')
    print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {PLOTS_DIR / 'heatmap_correlations.png'}")

    # ==================== 8. –ú–û–î–ï–õ–¨: –û–ë–£–ß–ï–ù–ò–ï ====================
    print("\n[8/9] ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...")
    print("‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã...")

    model_results = model_service.train_models(df)

    print(f"\n  ‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"  üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {model_results['best_model']}")
    print(f"  üìä –£–ª—É—á—à–µ–Ω–∏–µ: {model_results['improvement']:.1f}%")

    print("\n  üìà –ú–µ—Ç—Ä–∏–∫–∏ Linear Regression:")
    lr_metrics = model_results['metrics']['linear_regression']
    print(f"    R¬≤ Score: {lr_metrics['r2_score']:.4f}")
    print(f"    RMSE:     {lr_metrics['rmse']:.2f}")
    print(f"    MAE:      {lr_metrics['mae']:.2f}")

    print("\n  üìà –ú–µ—Ç—Ä–∏–∫–∏ Random Forest:")
    rf_metrics = model_results['metrics']['random_forest']
    print(f"    R¬≤ Score: {rf_metrics['r2_score']:.4f}")
    print(f"    RMSE:     {rf_metrics['rmse']:.2f}")
    print(f"    MAE:      {rf_metrics['mae']:.2f}")

    # Feature Importance
    importance = model_service.get_feature_importance(top_n=10)
    print("\n  üéØ –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for i, (feature, imp) in enumerate(importance['top_features'].items(), 1):
        bar = '‚ñà' * int(imp * 50)
        print(f"    {i:2d}. {feature:20s}: {bar} {imp:.4f}")

    # ==================== 9. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ì–†–ê–§–ò–ö–ò ====================
    print("\n[9/9] üìä –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤...")

    # Feature Importance –≥—Ä–∞—Ñ–∏–∫
    features_list = list(model_results['features_used'])
    importances_list = [model_results['metrics']['feature_importance'][f] for f in features_list]

    feature_plot = plot_service.create_feature_importance_plot(features_list, importances_list)
    save_base64_image(feature_plot, 'feature_importance.png')
    print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {PLOTS_DIR / 'feature_importance.png'}")

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    predictions = model_service.get_predictions()
    comparison_plot = plot_service.create_comparison_plot(
        model_service.y_test,
        model_service.lr_pred,
        model_service.rf_pred
    )
    save_base64_image(comparison_plot, 'predictions_comparison.png')
    print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {PLOTS_DIR / 'predictions_comparison.png'}")

    # ==================== –ò–¢–û–ì–ò ====================
    print("\n" + "="*70)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û!")
    print("="*70)

    print(f"\nüìÇ –í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {PLOTS_DIR}")
    print("\nüìä –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print("  1. scatter_tempo_popularity.png   - Scatter plot")
    print("  2. histogram_loudness.png         - Histogram")
    print("  3. heatmap_correlations.png       - Heatmap")
    print("  4. feature_importance.png         - –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print("  5. predictions_comparison.png     - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")

    print("\nüìù –ö—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã:")
    print(f"  ‚Ä¢ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {model_results['best_model']}")
    print(f"  ‚Ä¢ R¬≤ Score: {rf_metrics['r2_score']:.4f}")
    print(f"  ‚Ä¢ –í–∞–∂–Ω–µ–π—à–∏–π –ø—Ä–∏–∑–Ω–∞–∫: {list(importance['top_features'].keys())[0]}")

    print("\nüåê –î–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
    print("  Backend:  cd backend && uvicorn api.main:app --reload")
    print("  Frontend: cd frontend && python -m http.server 8080")

    print("="*70)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(0)
    except Exception as e:
        print(f"\n\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)